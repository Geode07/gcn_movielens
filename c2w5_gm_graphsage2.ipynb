{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stellargraph as sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "print(stellargraph.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib as plt\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import collections\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import stellargraph as sg\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.layer import GraphSAGE\n",
    "from stellargraph.layer import HinSAGE\n",
    "from stellargraph.mapper import HinSAGELinkGenerator\n",
    "from stellargraph.mapper import GraphSAGENodeGenerator, FullBatchNodeGenerator, DirectedGraphSAGENodeGenerator\n",
    "from stellargraph.layer import GCN\n",
    "from stellargraph.data import EdgeSplitter\n",
    "from stellargraph.mapper import GraphSAGELinkGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dot, Reshape, Input, Embedding, Lambda, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Compare Graph Convolutional Network (GCN) and Sci-kit Learn's Surpise Library for Movie Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will compare the hand crafted recsys classes developed in Module 3 against the GCN model built from the StellarGraph library and the Sci-kit learn Surprise library. The dataset used is the MovieLens 100k dataset.\n",
    "\n",
    "The motivation for this project is that despite best efforts, RMSE my Module 3 modules was still too high and I wanted to see if more effective models could be built. Part 1 will walk through the GCN model and Part 2 will walk through the Surprise model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: GCN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical(df_X, _X):\n",
    "    values = np.array(df_X[_X])\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values) # integer encode\n",
    "    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False) # binary encode\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    df_X = df_X.drop(_X, 1)\n",
    "    for j in range(integer_encoded.max() + 1):\n",
    "        df_X.insert(loc=j + 1, column=str(_X) + str(j + 1), value=onehot_encoded[:, j])\n",
    "    return df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This new file below was sourced from https://github.com/hadoov/GHRS/blob/main/datasets/ml-100k/ua.base - links users, movies and ratings\n",
    "df_ua = pd.read_csv('data/ua.base', sep='\\t', engine='python', names=['user_id', 'movie_id', 'rating', 'timestamp']).rename(columns={'user_id': 'uID', 'movie_id': 'mID'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to acknowledge this example of preparing MovieLens data for GCN modeling: https://github.com/hadoov/GHRS/blob/main/datasets/ml-100k/ua.base. I used this as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MV_users = pd.read_csv('data/users.csv').rename(columns={'accupation': 'job'})\n",
    "MV_movies = pd.read_csv('data/movies.csv').drop(columns = ['title', 'year']).sort_values(by='mID')\n",
    "\n",
    "#Not using these files\n",
    "#test = pd.read_csv('data/test.csv')\n",
    "#train = pd.read_csv('data/train.csv')\n",
    "\n",
    "#from collections import namedtuple\n",
    "#Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "#data = Data(MV_users, MV_movies, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gerry\\miniconda3\\envs\\graphsage_env\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\Users\\gerry\\miniconda3\\envs\\graphsage_env\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\Users\\gerry\\miniconda3\\envs\\graphsage_env\\lib\\site-packages\\ipykernel_launcher.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n",
      "c:\\Users\\gerry\\miniconda3\\envs\\graphsage_env\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\Users\\gerry\\miniconda3\\envs\\graphsage_env\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "MV_users = convert_categorical(MV_users, 'job')\n",
    "MV_users = convert_categorical(MV_users, 'gender')\n",
    "MV_users['bin'] = pd.cut(MV_users['age'], [0, 10, 20, 30, 40, 50, 100], labels=['1', '2', '3', '4', '5', '6'])\n",
    "MV_users['age'] = MV_users['bin']\n",
    "\n",
    "MV_users = MV_users.drop('bin', 1)\n",
    "MV_users = convert_categorical(MV_users, 'age')\n",
    "MV_users = MV_users.drop('zip', 1)\n",
    "\n",
    "MV_users.set_index('uID', inplace=True)\n",
    "MV_movies.set_index('mID', inplace=True)\n",
    "\n",
    "# Adding a prefix to user and movie IDs\n",
    "MV_users.index = 'u' + MV_users.index.astype(str)\n",
    "MV_movies.index = 'm' + MV_movies.index.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intent of this data preparation is to ready the movie data for processing into a graph model with nodes and edges. User id and movie id were made into indexes and prefixed with 'u' and 'm' respectively. The user data was one-hot encoded for the better processing of the data. The movie data was also one-hot encoded for the better processing of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Sampled 80626 positive and 80626 negative edges. **\n",
      "** Sampled 9953 positive and 9953 negative edges. **\n"
     ]
    }
   ],
   "source": [
    "# Create node data dictionary\n",
    "node_data = {\n",
    "    'user': MV_users,\n",
    "    'movie': MV_movies\n",
    "}\n",
    "\n",
    "# Create edges with ratings\n",
    "edges = df_ua[['uID', 'mID', 'rating']].copy()\n",
    "edges.columns = ['source', 'target', 'rating']\n",
    "edges['source'] = 'u' + edges['source'].astype(str)\n",
    "edges['target'] = 'm' + edges['target'].astype(str)\n",
    "\n",
    "all_movie_ids = set(edges['target'])\n",
    "available_movie_ids = set(MV_movies.index)\n",
    "unmatched_movie_ids = all_movie_ids - available_movie_ids\n",
    "\n",
    "edges = edges[~edges['target'].isin(unmatched_movie_ids)]\n",
    "\n",
    "valid_sources = set(MV_users.index)\n",
    "valid_targets = set(MV_movies.index)\n",
    "edges = edges[edges['source'].isin(valid_sources) & edges['target'].isin(valid_targets)]\n",
    "\n",
    "# Create the graph\n",
    "G = sg.StellarGraph(nodes={'user': MV_users, 'movie': MV_movies}, edges=edges, edge_type_column='rating')\n",
    "\n",
    "# Split the graph into training and test sets\n",
    "edge_splitter = EdgeSplitter(G)\n",
    "G_train, edge_ids_train, edge_labels_train = edge_splitter.train_test_split(\n",
    "    p=0.9,  # 90% of edges for training\n",
    "    method=\"global\",\n",
    "    keep_connected=True\n",
    ")\n",
    "\n",
    "# Now split the remaining edges for testing\n",
    "G_test, edge_ids_test, edge_labels_test = edge_splitter.train_test_split(\n",
    "    p=0.1 / 0.9,  # 10% of the remaining 10% of edges for testing\n",
    "    method=\"global\",\n",
    "    keep_connected=True\n",
    ")\n",
    "\n",
    "# Create generators\n",
    "batch_size = 50\n",
    "num_samples = [10, 5]\n",
    "\n",
    "# Create the generator for the training graph\n",
    "train_generator = HinSAGELinkGenerator(G_train, batch_size, num_samples, head_node_types=[\"user\", \"movie\"])\n",
    "\n",
    "# Create the generator for the test graph\n",
    "test_generator = HinSAGELinkGenerator(G_test, batch_size, num_samples, head_node_types=[\"user\", \"movie\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HINSAGE GCN Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the HinSAGE model\n",
    "hinsage = HinSAGE(\n",
    "    layer_sizes=[32, 32],  # Adjust layer sizes as needed\n",
    "    generator=generator,\n",
    "    bias=True,\n",
    "    dropout=0.3,\n",
    ")\n",
    "\n",
    "# Create input and output tensors\n",
    "x_inp, x_out = hinsage.in_out_tensors()\n",
    "\n",
    "# Link prediction requires combining embeddings from both nodes\n",
    "prediction = Dot(axes=1, normalize=False)(x_out)\n",
    "prediction = Reshape((-1,))(prediction)\n",
    "\n",
    "# Build the Keras model\n",
    "model = Model(inputs=x_inp, outputs=prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='mean_squared_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, GCN was built on the graph model generated via StellarGraph, which handily splits the graph itself into training and test graphs. The model was then compiled and trained on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out only user-movie edges - needed because user-user, movie-movie edges were created as result of edge splitter\n",
    "corrected_edges_train = np.array([\n",
    "    [src, tgt] for src, tgt in edge_ids_train\n",
    "    if src.startswith('u') and tgt.startswith('m')\n",
    "])\n",
    "\n",
    "corrected_labels_train = edge_labels_train[\n",
    "    [i for i, (src, tgt) in enumerate(edge_ids_train) if src.startswith('u') and tgt.startswith('m')]\n",
    "]\n",
    "\n",
    "corrected_edges_test = np.array([\n",
    "    [src, tgt] for src, tgt in edge_ids_test\n",
    "    if src.startswith('u') and tgt.startswith('m')\n",
    "])\n",
    "\n",
    "corrected_labels_test = edge_labels_test[\n",
    "    [i for i, (src, tgt) in enumerate(edge_ids_test) if src.startswith('u') and tgt.startswith('m')]\n",
    "]\n",
    "\n",
    "# Create the training, testing generator\n",
    "train_gen = train_generator.flow(corrected_edges, corrected_labels, shuffle=True)\n",
    "test_flow = test_generator.flow(corrected_edges_test, corrected_labels_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting train graph_gen to the model, I needed to clean up the graph edges, because the edge split function created edges between users and users, movies and movies, which are not needed for this model. I filtered out only the user-movie edges and their corresponding labels. I then created the training and testing generators using the flow method of the train_generator and test_generator objects. The flow method returns a generator that yields batches of samples for training or testing. The flow method takes the edge IDs and labels as input and shuffles the data if needed. The train_gen and test_flow objects are used to fit the model to the training data and evaluate the model on the test data, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 - 12s - loss: 0.0365\n",
      "Epoch 2/20\n",
      "43/43 - 11s - loss: 0.0170\n",
      "Epoch 3/20\n",
      "43/43 - 11s - loss: 0.0098\n",
      "Epoch 4/20\n",
      "43/43 - 11s - loss: 0.0064\n",
      "Epoch 5/20\n",
      "43/43 - 12s - loss: 0.0038\n",
      "Epoch 6/20\n",
      "43/43 - 14s - loss: 0.0031\n",
      "Epoch 7/20\n",
      "43/43 - 13s - loss: 0.0022\n",
      "Epoch 8/20\n",
      "43/43 - 11s - loss: 0.0016\n",
      "Epoch 9/20\n",
      "43/43 - 11s - loss: 0.0013\n",
      "Epoch 10/20\n",
      "43/43 - 11s - loss: 9.6936e-04\n",
      "Epoch 11/20\n",
      "43/43 - 11s - loss: 7.7805e-04\n",
      "Epoch 12/20\n",
      "43/43 - 11s - loss: 6.1872e-04\n",
      "Epoch 13/20\n",
      "43/43 - 11s - loss: 5.7659e-04\n",
      "Epoch 14/20\n",
      "43/43 - 11s - loss: 4.8017e-04\n",
      "Epoch 15/20\n",
      "43/43 - 11s - loss: 4.0003e-04\n",
      "Epoch 16/20\n",
      "43/43 - 11s - loss: 3.0638e-04\n",
      "Epoch 17/20\n",
      "43/43 - 11s - loss: 2.8416e-04\n",
      "Epoch 18/20\n",
      "43/43 - 11s - loss: 2.7480e-04\n",
      "Epoch 19/20\n",
      "43/43 - 11s - loss: 2.3669e-04\n",
      "Epoch 20/20\n",
      "43/43 - 11s - loss: 1.9941e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=20,\n",
    "    verbose=2,\n",
    "    validation_data=None,  # Add validation data if available\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 12s 243ms/step - loss: 0.0784\n",
      "Test Metrics: 0.07835771888494492\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance on the test set\n",
    "test_metrics = model.evaluate(test_flow)\n",
    "print(\"Test Metrics:\", test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.2799489922067964\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'corrected_labels_test' contains the actual ratings for the test edges\n",
    "test_targets = corrected_labels_test\n",
    "# Make predictions using the trained model on the test set\n",
    "y_pred = model.predict(test_flow)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(test_targets, y_pred.flatten()))  # Ensure y_pred is correctly shaped\n",
    "print(\"Test RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE result of Test RMSE: 0.2799489922067964 is remarkably good. HINSAGE was chosen over GRAPHSAGE because my graph has 2 node tyoes: users, movies, and GRAPHSAGE can only handle graphs with 1 node type. This was a relatively small data set, on much larger data sets, I am not sure how HINSAGE would perform. Of course, with such a low RMSE the question of overfitting is highly relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Sci-kit Surpise Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD, SVDpp ,accuracy\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNWithZScore\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uID</th>\n",
       "      <th>mID</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90565</th>\n",
       "      <td>943</td>\n",
       "      <td>1047</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90566</th>\n",
       "      <td>943</td>\n",
       "      <td>1074</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90567</th>\n",
       "      <td>943</td>\n",
       "      <td>1188</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90568</th>\n",
       "      <td>943</td>\n",
       "      <td>1228</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90569</th>\n",
       "      <td>943</td>\n",
       "      <td>1330</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90570 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uID   mID  rating timestamp\n",
       "0        1     1     5.0      None\n",
       "1        1     2     3.0      None\n",
       "2        1     3     4.0      None\n",
       "3        1     4     3.0      None\n",
       "4        1     5     3.0      None\n",
       "...    ...   ...     ...       ...\n",
       "90565  943  1047     2.0      None\n",
       "90566  943  1074     4.0      None\n",
       "90567  943  1188     3.0      None\n",
       "90568  943  1228     3.0      None\n",
       "90569  943  1330     3.0      None\n",
       "\n",
       "[90570 rows x 4 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_ua[['uID', 'mID','rating']], reader)\n",
    "pd.DataFrame(data.__dict__['raw_ratings'], columns=['uID', 'mID','rating','timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise has as specific format for the data, so above I converted the data to that format. I reused the same data imported at top of notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "benchmark = []\n",
    "\n",
    "for algo in [SVD(), SVDpp(), KNNBasic(), KNNWithMeans(), KNNWithZScore()]:\n",
    "    result = cross_validate(algo, data, cv=5)\n",
    "    results= pd.DataFrame.from_dict(result).mean(axis=0)\n",
    "    results = results.append(pd.Series([str(algo).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose SVD(), SVDpp(), KNNBasic(), KNNWithMeans(), KNNWithZScore() as the algorithms to compare, in order to provide a unique set of results as opposed to benchmarking the content-based and collaborative filtering algorithms. I also want to acknowledge this excellent Surpise example that inspired me: https://github.com/jadecebeci/Movie-Recommender-System/blob/main/Movie_Recommender_Modeling.ipynb. The results are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_results = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>0.921214</td>\n",
       "      <td>0.722533</td>\n",
       "      <td>142.534636</td>\n",
       "      <td>2.856097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.938674</td>\n",
       "      <td>0.739939</td>\n",
       "      <td>3.695797</td>\n",
       "      <td>0.198495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>0.951430</td>\n",
       "      <td>0.746179</td>\n",
       "      <td>0.487074</td>\n",
       "      <td>2.862678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>0.951798</td>\n",
       "      <td>0.749973</td>\n",
       "      <td>0.397178</td>\n",
       "      <td>2.842386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>0.983156</td>\n",
       "      <td>0.776521</td>\n",
       "      <td>0.435661</td>\n",
       "      <td>2.673625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               test_rmse  test_mae    fit_time  test_time\n",
       "Algorithm                                                \n",
       "SVDpp           0.921214  0.722533  142.534636   2.856097\n",
       "SVD             0.938674  0.739939    3.695797   0.198495\n",
       "KNNWithZScore   0.951430  0.746179    0.487074   2.862678\n",
       "KNNWithMeans    0.951798  0.749973    0.397178   2.842386\n",
       "KNNBasic        0.983156  0.776521    0.435661   2.673625"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Below is summary of rec sys models tested and their performance:\n",
    "\n",
    "|Method|RMSE|\n",
    "|:----|:--------:|\n",
    "|Baseline, $Y_p$= |1.2585510334053043 |\n",
    "|Baseline, $Y_p=\\mu_u$|1.0352910334228647 |\n",
    "|Content based, item-item|1.012502820366462 |\n",
    "|Collaborative, cosine|1.0023580719424758 |\n",
    "|Collaborative, jaccard, $M_r\\geq 3$|1.0400814568358727  |\n",
    "|Collaborative, jaccard, $M_r\\geq 1$|1.0399281016619402  |\n",
    "|Collaborative, jaccard, $M_r$|1.0399281016619402  |\n",
    "|SVDpp (Surprise)|0.921214 |\n",
    "|SVD (Surprise) |0.938674 |\n",
    "|KNNWithZScore\t(Surprise)|0.951430 |\n",
    "|KNNWithMeans (Surprise)|0.951798 |\n",
    "|KNNBasic (Surprise)|0.983156 |\n",
    "|StellarGraph HINSAGE GCN |0.2799489922067964|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphsage",
   "language": "python",
   "name": "graphsage_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
